---
title: "STAT-253_FP_stock"
author: "Yixiao Wang"
date: "2/26/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

a & b.

```{r}
# library statements 
library(readr)
library(ggplot2)
library(dplyr)
library(tidymodels)
library(TTR)
tidymodels_prefer()

set.seed(123)

# read in data
Stock <- read_csv("indexData.csv")
```

```{r}
# data cleaning
Stock_clean <- Stock %>% 
  select(Index : Close) %>% 
  na.omit() %>% 
  filter(Open != "null",
         High != "null",
         Low != "null",
         Close != "null")

Stock_clean %>% 
  group_by(Index) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n))

Stock_clean <- Stock_clean %>% 
  filter(Index == "NYA") %>% 
  mutate(Open = as.numeric(Open),
         High = as.numeric(High),
         Low = as.numeric(Low),
         Close = as.numeric(Close))

Stock_clean %>% 
  ggplot() +
  geom_line(aes(x = Date,
                y = Open))

Stock_clean <- Stock_clean %>% 
  mutate(Date = as.numeric(Date))
```

```{r}
Stock_clean <- Stock_clean %>% 
  mutate(rsi = RSI(Close, n=14)) %>% 
  na.omit()
```

```{r}
# creation of cv folds
Stock_clean_5 <- vfold_cv(Stock_clean, v = 5)
```

```{r}
# model spec
lm_spec <-
    linear_reg() %>%
    set_engine(engine = "lm") %>% 
    set_mode("regression")

lm_lasso_spec <- 
  linear_reg() %>%
  set_args(mixture = 1, penalty = tune()) %>%
  set_engine(engine = 'glmnet') %>%
  set_mode('regression') 
```

```{r}
# recipes
data_rec <- recipe(Close ~ Date + Open + High + Low + rsi, data = Stock_clean) %>%
  step_nzv(all_predictors()) %>%
  step_normalize(all_numeric_predictors())
  #step_corr(all_numeric_predictors())

# workflows
lm_wf <- workflow() %>%
  add_recipe(data_rec) %>%
  add_model(lm_spec) 

lm_lasso_wf <- workflow() %>% 
  add_recipe(data_rec) %>%
  add_model(lm_lasso_spec)
```

```{r}
# fit & tune models
fit_lm_model <- fit(lm_wf, Stock_clean)
tidy(fit_lm_model)

lm_lasso_fit <- lm_lasso_wf %>% 
  fit(data = Stock_clean)

glmnet_output <- lm_lasso_fit %>% extract_fit_parsnip() %>% pluck('fit') 

lambdas <- glmnet_output$lambda
coefs_lambdas <- 
  coefficients(glmnet_output, s = lambdas )  %>% 
  as.matrix() %>%  
  t() %>% 
  as.data.frame() %>% 
  mutate(lambda = lambdas ) %>% 
  select(lambda, everything(), -`(Intercept)`) %>% 
  pivot_longer(cols = -lambda, 
               names_to = "term", 
               values_to = "coef") %>%
  mutate(var = map_chr(stringr::str_split(term,"_"),~.[1]))

coefs_lambdas %>%
  ggplot(aes(x = lambda, y = coef, group = term, color = var)) +
  geom_line() +
  theme_classic() + 
  theme(legend.position = "bottom", legend.text=element_text(size=8))
```

```{r}
#  calculate/collect CV metrics
#  For linear regression
lm_result_5 <- fit_resamples(lm_wf,
                             resamples = Stock_clean_5, 
                             metrics = metric_set(rmse, rsq, mae))

collect_metrics(lm_result_5)


#  for LASSO
penalty_grid <- grid_regular(
  penalty(range = c(-3, 3)),
  levels = 20)

tune_res <- tune_grid(
  lm_lasso_wf, 
  resamples = Stock_clean_5,
  metrics = metric_set(rmse, mae),
  grid = penalty_grid 
)

autoplot(tune_res) + theme_classic()

best_penalty <- select_best(tune_res, metric = 'rmse')

final_wf <- finalize_workflow(lm_lasso_wf, best_penalty)

final_fit <- fit(final_wf, data = Stock_clean)

tidy(final_fit)

tune_res %>% collect_metrics(summarize = TRUE) %>% 
  filter(.metric == "rmse") %>% 
  summarize(mean = mean(mean))
```