---
title: "Final Project Code"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# library statements 
library(readr)
library(ggplot2)
library(dplyr)
library(tidymodels)
library(vip)
library(ranger)
<<<<<<< HEAD
library(rpart.plot)
=======
library(broom)
library(e1071)
library(caTools)
library(class)

tidymodels_prefer()
theme_set(theme_bw())
>>>>>>> a9ad5d42c5f391703323a877d4de2874412fa557

set.seed(123)

# read in data
Titanic <- read_csv("Data/train.csv")
```

```{r}
# data cleaning
Titanic_clean <- Titanic %>% 
  select(Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked) %>% 
    na.omit()

Titanic_clean

# creation of cv folds
Titanic_clean_5 <- vfold_cv(Titanic_clean, v = 5)

# recipes
data_rec <- recipe(Fare ~ ., data = Titanic_clean) %>%
  step_nzv(all_predictors()) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_corr(all_numeric_predictors())
```

# Classification

## RANDOM FOREST

```{r}
# Model Specification
rf_spec <- rand_forest() %>%
  set_engine(engine = 'ranger') %>% 
  set_args(mtry = NULL, # size of random subset of variables; default is floor(sqrt(number of total predictors))
           trees = 100, # Number of trees
           min_n = 2,
           probability = FALSE, # FALSE: get hard predictions (not needed for regression)
           importance = 'impurity') %>% # we'll come back to this at the end
  set_mode('classification') # change this for regression
```

```{r}
Titanic_clean <-Titanic_clean %>%
  mutate(Survived = as.factor(Survived))
```

```{r}
titanic_rec <- recipe(Survived ~ ., data = Titanic_clean)

# Workflows
titanic_wf_2 <- workflow() %>%
  add_model(rf_spec %>% set_args(mtry = 2)) %>%
  add_recipe(titanic_rec)
```

```{r}
set.seed(123) # make sure to run this before each fit so that you have the same 1000 trees
Titanic_fit <- fit(titanic_wf_2, data = Titanic_clean)
```

```{r}
rf_OOB_output <- function(fit_model, truth){
    tibble(
          .pred_class = fit_model %>% extract_fit_engine() %>% pluck('predictions'), #OOB predictions
          class = truth
      )
}

#check out the function output
rf_output <- rf_OOB_output(Titanic_fit, Titanic_clean %>% pull(Survived))
```

```{r}
data_rf_OOB_output <-  rf_output %>% 
    accuracy(truth = class, estimate = .pred_class)
```


```{r}
titanic_output2 <- titanic_wf_2 %>% 
  update_model(rf_spec %>% set_args(importance = "permutation")) %>% #based on permutation
  fit(data = Titanic_clean) %>% 
    extract_fit_engine() 

titanic_output2 %>% 
    vip(num_features = 30) + theme_classic()


titanic_output2 %>% vip::vi() %>% head()
titanic_output2 %>% vip::vi() %>% tail()
```

```{r}
rf_OOB_output(Titanic_fit, Titanic_clean %>% pull(Survived)) %>%
    conf_mat(truth = class, estimate= .pred_class)
```

## DECISION TREE


```{r}
ct_spec <- decision_tree() %>%
  set_engine(engine = 'rpart') %>%
  set_args(cost_complexity = NULL,  #default is 0.01 (used for pruning a tree)
           min_n = NULL, #min number of observations to try split: default is 20 [I think the documentation has a typo and says 2]  (used to stop early)
           tree_depth = NULL) %>% #max depth (max number of splits to get to any final group: default is 30 (used to stop early)
  set_mode('classification') # change this for regression tree
```

```{r}
titan_rec <- recipe(Survived ~ ., data = Titanic_clean) %>%
  #step_unknown(all_nominal_predictors()) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors())

titan_wf <- workflow() %>%
  add_model(ct_spec) %>%
  add_recipe(titan_rec)
```

<<<<<<< HEAD
```{r}
titan_fit <- titan_wf %>%
  fit(data = Titanic_clean)
```

```{r}
titan_fit %>%
  extract_fit_engine() %>%
  rpart.plot()
```
=======
## KNN

```{r}
# Model Specification
knn_spec <- 
  nearest_neighbor() %>%
  set_args(neighbors = tune()) %>% 
  set_engine(engine = 'kknn') %>%
  set_mode('classification') 

# Recipe
data_rec2 <- recipe(Survived ~ ., data = Titanic_clean) %>%
  step_nzv(all_predictors()) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_corr(all_numeric_predictors())

# Workflow (Recipe + Model)
knn_wf <- workflow() %>%
  add_model(knn_spec) %>% 
  add_recipe(data_rec)
```

```{r}
Titanic_clean_52 <- vfold_cv(Titanic_clean, v = 5)

penalty_grid <- grid_regular(
  neighbors(range = c(1, 100)),
  levels = 20)

knn_fit_cv <- tune_grid(knn_wf,
                        resamples = Titanic_clean_52,
                        grid = penalty_grid)
>>>>>>> a9ad5d42c5f391703323a877d4de2874412fa557

knn_fit_cv %>% 
  collect_metrics()
```


# Regression

## OLS

```{r}
# model spec for OLS
lm_spec <-
  linear_reg() %>%
  set_engine(engine = "lm") %>%
  set_mode("regression")

# workflow for OLS
lm_wf <- workflow() %>%
  add_recipe(data_rec) %>%
  add_model(lm_spec) 
```

```{r}
# Fit the OLS model
fit_lm_model <- fit(lm_wf, Titanic_clean)
```

```{r}
# Present the OLS model result and its metrics
tidy(fit_lm_model)
glance(fit_lm_model)
```

```{r}
#  Calculate and collect CV metrics for OLS
lm_result_5 <- fit_resamples(lm_wf,
                             resamples = Titanic_clean_5,
                             metrics = metric_set(rmse, rsq, mae))

collect_metrics(lm_result_5)
```

```{r}
# Visualize the residual plot for OLS
lm_model_output <- fit_lm_model %>%
  predict(new_data = Titanic_clean) %>%
  bind_cols(Titanic_clean) %>%
  mutate(resid = Fare - .pred)

ggplot(lm_model_output, aes(x = .pred, y = resid)) +
  geom_point() +
  geom_smooth() +
  geom_hline(yintercept = 0, color = "red") +
  theme_classic()
```

## LASSO

```{r}
# model spec for LASSO
lm_lasso_spec <-
  linear_reg() %>%
  set_args(mixture = 1, penalty = tune()) %>%
  set_engine(engine = 'glmnet') %>%
  set_mode('regression') 

# workflows for LASSO
lm_lasso_wf <- workflow() %>%
  add_recipe(data_rec) %>%
  add_model(lm_lasso_spec)
```

```{r}
# Fit the LASSO model
lm_lasso_fit <- lm_lasso_wf %>%
  fit(data = Titanic_clean)
```

```{r}
# Tune the LASSO model
glmnet_output <-
  lm_lasso_fit %>% extract_fit_parsnip() %>% pluck('fit')

lambdas <- glmnet_output$lambda
coefs_lambdas <-
  coefficients(glmnet_output, s = lambdas)  %>%
  as.matrix() %>%
  t() %>%
  as.data.frame() %>%
  mutate(lambda = lambdas) %>%
  select(lambda, everything(),-`(Intercept)`) %>%
  pivot_longer(cols = -lambda,
               names_to = "term",
               values_to = "coef") %>%
  mutate(var = map_chr(stringr::str_split(term, "_"),  ~ .[1]))

coefs_lambdas %>%
  ggplot(aes(
    x = lambda,
    y = coef,
    group = term,
    color = var
  )) +
  geom_line() +
  theme_classic() +
  theme(legend.position = "bottom", legend.text = element_text(size = 8))
```

```{r}
# Visualize the best penalty term
penalty_grid <- grid_regular(penalty(range = c(-3, 3)),
                             levels = 20)

tune_res <- tune_grid(
  lm_lasso_wf,
  resamples = Titanic_clean_5,
  metrics = metric_set(rmse, mae, rsq),
  grid = penalty_grid
)

autoplot(tune_res) + theme_classic()
```

```{r}
# Present the LASSO model result
best_penalty <- select_best(tune_res, metric = 'rmse')
final_wf <- finalize_workflow(lm_lasso_wf, best_penalty)
final_fit <- fit(final_wf, data = Titanic_clean)
tidy(final_fit)
```

```{r}
#  Calculate and collect CV metrics for LASSO
lasso_result_5 <- tune_res %>% collect_metrics(summarize = TRUE) %>%
  na.omit() %>% 
  group_by(.metric) %>% 
  summarize(mean = mean(mean))
lasso_result_5
```

```{r}
# Visualize the residual plot for LASSO
lasso_model_output <- final_fit %>%
  predict(new_data = Titanic_clean) %>%
  bind_cols(Titanic_clean) %>%
  mutate(resid = Fare - .pred)

ggplot(lasso_model_output, aes(x = .pred, y = resid)) +
  geom_point() +
  geom_smooth() +
  geom_hline(yintercept = 0, color = "red") +
  theme_classic()
```

## GAMs

```{r}
# GAM model using mgcv
gam_spec <-
  gen_additive_mod() %>%
  set_engine(engine = 'mgcv') %>%
  set_mode('regression')

gam_mod <- fit(gam_spec,
               Fare ~ Survived + Pclass + SibSp + Parch + Sex + Embarked + s(Age),
               data = Titanic_clean)
```

```{r}
# Present the GAM model result
gam_mod %>% pluck('fit') %>% summary() 
```

```{r}
# Visualize the evaluation plots for GAMs
par(mfrow = c(2, 3))
gam_mod %>% pluck('fit') %>% mgcv::gam.check()
gam_mod %>% pluck('fit') %>% plot()
```

```{r}
# Visualize the residual plot for GAMs
gam_mod_output <- Titanic_clean %>%
  bind_cols(predict(gam_mod, new_data = Titanic_clean)) %>%
  mutate(resid = Fare - .pred)

ggplot(gam_mod_output, aes(x = Age, y = resid)) +
  geom_point() +
  geom_smooth() +
  geom_hline(yintercept = 0, color = "red") +
  theme_classic()

ggplot(gam_mod_output, aes(x = Parch, y = resid)) +
  geom_point() +
  geom_smooth() +
  geom_hline(yintercept = 0, color = "red") +
  theme_classic()

ggplot(gam_mod_output, aes(x = .pred, y = resid)) +
  geom_point() +
  geom_smooth() +
  geom_hline(yintercept = 0, color = "red") +
  theme_classic()
```
```{r}
#  Calculate and collect CV metrics for GAMs
spline_lm_spec <-
  linear_reg() %>%
  set_engine(engine = 'lm') %>%
  set_mode('regression')

spline_rec <- data_rec %>%
  step_naomit(all_numeric_predictors(), skip = FALSE) %>%
  step_ns(Age, deg_free = 2.694)

spline_wf <- workflow() %>%
  add_model(spline_lm_spec) %>%
  add_recipe(spline_rec)

gam_result_5 <- fit_resamples(spline_wf,
              resamples = Titanic_clean_5,
              metrics = metric_set(mae, rmse, rsq))

gam_result_5 %>% collect_metrics()
```

# Evaluation

```{r}
# CV metrics for OLS
lm_result_5 %>%
  collect_metrics()

# CV metrics for LASSO
lasso_result_5

# CV metrics for GAMs
gam_result_5 %>% 
  collect_metrics()
```

```{r}
# RF from the internet
library(ggplot2)
library(randomForest)
library(tidyverse)

set.seed(1)
train <- read.csv("data/train.csv", stringsAsFactors=FALSE)
test  <- read.csv("data/test.csv",  stringsAsFactors=FALSE)

extractFeatures <- function(data) {
  features <- c("Pclass",
                "Age",
                "Sex",
                "Parch",
                "SibSp",
                "Fare",
                "Embarked")
  fea <- data[,features]
  fea$Age[is.na(fea$Age)] <- -1
  fea$Fare[is.na(fea$Fare)] <- median(fea$Fare, na.rm=TRUE)
  fea$Embarked[fea$Embarked==""] = "S"
  fea$Sex      <- as.factor(fea$Sex)
  fea$Embarked <- as.factor(fea$Embarked)
  return(fea)
}

rf <- randomForest(extractFeatures(train), as.factor(train$Survived), ntree=100, importance=TRUE)

submission <- data.frame(PassengerId = test$PassengerId)
submission$Survived <- predict(rf, extractFeatures(test))

train <- train %>% 
  mutate(pred = predict(rf, extractFeatures(train))) %>% 
  select(pred, Survived)

imp <- importance(rf, type=1)
featureImportance <- data.frame(Feature=row.names(imp), Importance=imp[,1])

p <- ggplot(featureImportance, aes(x=reorder(Feature, Importance), y=Importance)) +
     geom_bar(stat="identity", fill="#53cfff") +
     coord_flip() + 
     theme_light(base_size=20) +
     xlab("") +
     ylab("Importance") + 
     ggtitle("Random Forest Feature Importance\n") +
     theme(plot.title=element_text(size=18))

p

submission

train %>% 
  mutate(correct = ifelse(pred == Survived, "correct", "incorrect")) %>% 
  group_by(correct) %>% 
  summarize(sum = n())

rf
```